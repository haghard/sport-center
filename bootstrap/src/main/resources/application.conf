akka {
    actor {
      serializers {
        crawler-response = "crawler.serializer.CrawlerResponseSerializer"
        change-set-event = "domain.serializer.ChangeSetEventSerializer"
        result-added-event = "domain.serializer.ResultAddedEventSerializer"
        campaign-persisted-event = "domain.serializer.CampaignPersistedSerializer"
      }

      serialization-bindings {
        "crawler.writer.CrawlerGuardian$CrawlerResponse" = crawler-response
        "domain.update.DomainWriter$BeginTransaction" = change-set-event
        "domain.TeamAggregate$ResultAdded" = result-added-event
        "domain.CrawlerCampaign$CampaignPersistedEvent" = campaign-persisted-event
      }
    }

  logConfigOnStart = on

  logger-startup-timeout = 10000

  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
  loglevel = DEBUG
  stdout-loglevel = DEBUG

  log-dead-letters = off

  actor {
    provider = akka.cluster.ClusterActorRefProvider
  }

  scheduler-dispatcher {
    # Dispatcher is the name of the event-based dispatcher
    type = Dispatcher
    # What kind of ExecutionService to use
    executor = "fork-join-executor"
    # Configuration for the fork join pool
    fork-join-executor {
      # Min number of threads to cap factor-based parallelism number to
      parallelism-min = 2
      # Parallelism (threads) ... ceil(available processors * factor)
      parallelism-factor = 2.0
      # Max number of threads to cap factor-based parallelism number to
      parallelism-max = 10
    }
    throughput = 100
  }

  http-dispatcher {
    type = Dispatcher
    executor = "fork-join-executor"
    fork-join-executor {
      parallelism-min = 4
      parallelism-factor = 2.0
      parallelism-max = 20
    }
    throughput = 100
  }

  remote {
    log-remote-lifecycle-events = off
    netty.tcp {
      hostname = "127.0.0.1"
      port = 0
    }
  }

  cluster {
    seed-nodes = [
      "akka.tcp://SCenter@127.0.0.1:2551",
      "akka.tcp://SCenter@127.0.0.1:2552"]

    auto-down-unreachable-after = 10s

    sharding {
      role = "Domain"
      #Timeout of the shard rebalancing process.
      remember-entities = on
      handoff-timeout = 60 s

      # How often the coordinator saves persistent snapshots, which are
      # used to reduce recovery times
      snapshot-interval = 60 s

      # Rebalance check is performed periodically with this interval
      rebalance-interval = 30 s
    }
  }

  persistence {
    journal.plugin = "cassandra-journal"
    snapshot-store.plugin = "cassandra-snapshot-store"
  }


  http {
    session {
      max-age = 600 s
    }
  }
}

cassandra-journal {
  cluster-id = "haghard_cluster"

  #connect-retry-delay = 20000 ms
  #replication-strategy
  #replication-factor
  #data-center-replication-factors

  # FQCN of the cassandra journal plugin
  class = "akka.persistence.cassandra.journal.CassandraJournal"

  # Name of the keyspace to be created/used by the journal
  keyspace = "sport_center"

  # Name of the table to be created/used by the journal
  table = "sport_center_journal"

  replication-strategy =  "SimpleStrategy"

  #replication-strategy = "NetworkTopologyStrategy"

  # Replication factor list for data centers, e.g. ["dc1:3", "dc2:2"]. Is only used when replication-strategy is NetworkTopologyStrategy.
  #data-center-replication-factors = ["west", "east"]

  # To limit the Cassandra hosts this plugin connects with to a specific datacenter.
  # (DCAwareRoundRobinPolicy withLocalDc)
  # The id for the local datacenter of the Cassandra hosts it should connect to.
  # By default, this property is not set resulting in Datastax's standard round robin policy being used.
  local-datacenter = "west"

  # Replication factor to use when creating a keyspace
  replication-factor = 2

  # Write consistency level
  write-consistency = "ANY"

  #Data must be written to at least one node, but permits writes via hinted
  #handoff. Effectively allows a write to any node, even if all nodes containing
  #the replica are down. A subsequent read might be impossible if all replica nodes are down

  # Read consistency level
  read-consistency = "ONE"

  # Maximum number of entries per partition (= columns per row).
  target-partition-size = 500000

  # Maximum size of result set
  max-result-size = 50001


  # Maximum size of result set during replay
  max-result-size-replay = 50001

  # The query journal to use when recoverying
  query-plugin = "cassandra-query-journal"


  # Dispatcher for the plugin actor.
  plugin-dispatcher = "akka.actor.default-dispatcher"

  # Dispatcher for fetching and replaying messages
  replay-dispatcher = "akka.persistence.dispatchers.default-replay-dispatcher"
}

cassandra-snapshot-store {
  cluster-id = "haghard_cluster"

  # FQCN of the cassandra snapshot store plugin
  class = "akka.persistence.cassandra.snapshot.CassandraSnapshotStore"

  # Name of the keyspace to be created/used by the snapshot store
  keyspace = "sport_center"

  # Name of the table to be created/used by the snapshot store
  table = "sport_center_snapshot"

  # Replication factor to use when creating a keyspace
  replication-factor = 2

  # Write consistency level
  write-consistency = "ANY"

  # Read consistency level
  read-consistency = "ONE"

  replication-strategy = "SimpleStrategy"

  # Maximum number of entries per partition (= columns per row).
  target-partition-size = 500000

  # Maximum size of result set
  max-result-size = 50001

  # Maximum size of result set during replay
  max-result-size-replay = 50001


  # Maximum number of snapshot metadata to load per recursion (when trying to
  # find a snapshot that matches specified selection criteria). Only increase
  # this value when selection criteria frequently select snapshots that are
  # much older than the most recent snapshot i.e. if there are much more than
  # 10 snapshots between the most recent one and selected one. This setting is
  # only for increasing load efficiency of snapshots.
  max-metadata-result-size = 10

  # Dispatcher for the plugin actor.
  plugin-dispatcher = "cassandra-snapshot-store.default-dispatcher"

  # Default dispatcher for plugin actor.
  default-dispatcher {
    type = Dispatcher
    executor = "fork-join-executor"
    fork-join-executor {
      parallelism-min = 2
      parallelism-max = 8
    }
  }
}

scheduler-dispatcher {
  type = Dispatcher
  executor = "fork-join-executor"
  fork-join-executor {
    parallelism-min = 2
    parallelism-factor = 2.0
    parallelism-max = 4
  }
  throughput = 100
}


cassandra-query-journal {
  # Implementation class of the Cassandra ReadJournalProvider
  class = "akka.persistence.cassandra.query.CassandraReadJournalProvider"

  # Absolute path to the write journal plugin configuration section
  write-plugin = "cassandra-journal"

  # New events are retrieved (polled) with this interval.
  refresh-interval = 5s

  # Read consistency level
  read-consistency = "ONE"

  eventual-consistency-delay = 10s
}

stream-dispatcher {
  type = Dispatcher
  executor = "fork-join-executor"
  fork-join-executor {
    parallelism-min = 2
    parallelism-factor = 2.0
    parallelism-max = 4
  }
  throughput = 100
}

hystrix-stream-dispatcher {
  type = Dispatcher
  executor = fork-join-executor
  fork-join-executor {
    parallelism-min = 2
    parallelism-factor = 2.0
    parallelism-max = 4
  }
  throughput = 100
}

crawler-dispatcher {
  type = PinnedDispatcher
  executor = thread-pool-executor
}

discovery {
  http-port = [8000, 8100]
  ops-timeout = 3 s
}

http {
  session = "56feyahK678k23gsdfhfu456gwedqujs58gdethi0kfdcswerwsfhjkk9uredw3423qs35j56k343HF69HssdfgdfuihhnjnzdfgsdflkiuertHKhLKJgFihjuu8y7gmlkahterlijbsldd07"
  salt = "eJHty45wJseq3eawscxvNdf45eMKLw34j45sdfg"
  ttl = 1200
  session = ${?SERVER_SECRET}
  salt = ${?SALT}
}

timeouts {
  results = 1 s
  standings = 1 s
}